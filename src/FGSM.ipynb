{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoge/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [.2] #epsilons：ピクセル単位のノイズの大きさ\n",
    "pretrained_model = \"lenet_mnist_model.pth\" #事前学習済みMNISTモデル(重みパラメータ)\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LeNet Model 定義\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) #畳み込み層nn.Conv2d(入力のチャネル数, 出力のチャネル数，カーネルの1辺のサイズ)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d() #過学習を防ぐためにいくつかのノードを無効にする\n",
    "        self.fc1 = nn.Linear(320, 50) #全結合層nn.Linear(入力のサイズ(20channel×4height×4width), 出力サイズ) height, weightについては計算して事前に出す\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) #活性化関数Relu, Maxプーリング\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320) #サイズを調整x.view(-1, 指定するサイズ)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# MNISTのTest datasetと dataloaderの定義\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])), \n",
    "        batch_size=1, shuffle=False)\n",
    "\n",
    "# 使うデバイス（CPUかGPUか）の定義\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# ネットワークの初期化\n",
    "model = Net().to(device)\n",
    "\n",
    "# 訓練済みモデルのロード\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# モデルを評価モードに設定。本チュートリアルの例では、これはドロップアウト層等を評価モードにするのに必要\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM による攻撃用のコード\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # データの勾配の各要素のsign値を取得します\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # 入力画像の各ピクセルを調整して、ノイズが追加された画像を作成します\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # [0,1]の範囲になるようデータをクリップします\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # ノイズが追加された画像を返します\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM による攻撃用のコード\n",
    "def fgsm_attack2(image, epsilon, data_grad):\n",
    "    # データの勾配の各要素のsign値を取得します\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # 入力画像の各ピクセルを調整して、ノイズが追加された画像を作成します\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # [0,1]の範囲になるようデータをクリップします\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # ノイズが追加された画像を返します\n",
    "    threshold = torch.Tensor([0.7]).to(\"cuda\")\n",
    "    return (perturbed_image > threshold).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM による攻撃用のコード\n",
    "def fgsm_attack3(image, epsilon, data_grad):\n",
    "    # データの勾配の各要素のsign値を取得します\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # 入力画像の各ピクセルを調整して、ノイズが追加された画像を作成します\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # [0,1]の範囲になるようデータをクリップします\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # ノイズが追加された画像を返します\n",
    "    threshold = torch.Tensor([0.5]).to(\"cuda\")\n",
    "    max_v = torch.Tensor([0.95]).to(\"cuda\")\n",
    "    min_v = torch.Tensor([0.05]).to(\"cuda\")\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            if (max_v > perturbed_image[0][0][i][j]) & (perturbed_image[0][0][i][j] > threshold):\n",
    "                perturbed_image[0][0][i][j] = max_v\n",
    "            if (threshold > perturbed_image[0][0][i][j]) & (perturbed_image[0][0][i][j] > min_v):\n",
    "                perturbed_image[0][0][i][j] = min_v\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack4(image, data_grad):\n",
    "    data_grad_sum = 0\n",
    "    for i in data_grad[0][0]:\n",
    "        for j in i:\n",
    "            data_grad_sum += j\n",
    "    data_grad_avg = data_grad_sum / (28 * 28)\n",
    "    perturbed_image = image + (data_grad > data_grad_avg).float() - (data_grad < -data_grad_avg).float()\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack5(image, data_grad):\n",
    "    data_grad_sort = []\n",
    "    for i in data_grad[0][0]:\n",
    "        for j in i:\n",
    "            data_grad_sort.append(j)\n",
    "    data_grad_sort.sort()\n",
    "    threshold_p = data_grad_sort[5]\n",
    "    threshold_n = data_grad_sort[778]\n",
    "    perturbed_image = image + (data_grad > threshold_p).float() - (data_grad < threshold_n).float()\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2( model, device, test_loader, epsilon ):\n",
    "\n",
    "    # 精度カウンター\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    # k = 0\n",
    "\n",
    "    # テスト用データセット内の全てのサンプルをループします\n",
    "    for data, target in test_loader:\n",
    "        # if k==200:\n",
    "        #     break\n",
    "        # k += 1\n",
    "\n",
    "        # データとラベルをデバイス（CPUもしくはGPU）に送信します\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # テンソルの requires_grad 属性を設定します。攻撃者にとっては重要な設定です。\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # データをモデルに順伝播させます\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # 最大の確率のインデックスを取得します。\n",
    "\n",
    "        # 最初から予測が間違っている場合、攻撃する必要がないため次のイテレーションに進みます。\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # 損失を計算します\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # 既存の勾配を全てゼロにします\n",
    "        model.zero_grad()\n",
    "\n",
    "        # 逆伝播させてモデルの勾配を計算します\n",
    "        loss.backward()\n",
    "\n",
    "        # データの勾配を取得します\n",
    "        data_grad = data.grad.data\n",
    "        \n",
    "        # FGSMによる攻撃の関数を呼び出します\n",
    "        perturbed_data = fgsm_attack4(data, data_grad)\n",
    "\n",
    "        #2値化\n",
    "        # threshold = torch.Tensor([0.7]).to(\"cuda\")\n",
    "        # perturbed_data = (perturbed_data > threshold).float()\n",
    "        \n",
    "        # threshold = torch.Tensor([0.35]).to(\"cuda\")\n",
    "        # max_v = torch.Tensor([0.95]).to(\"cuda\")\n",
    "        # min_v = torch.Tensor([0.05]).to(\"cuda\")\n",
    "        # for i in range(28):\n",
    "        #     for j in range(28):\n",
    "        #         if (max_v > perturbed_data[0][0][i][j]) & (perturbed_data[0][0][i][j] > threshold):\n",
    "        #             perturbed_data[0][0][i][j] = max_v\n",
    "        #         if (threshold > perturbed_data[0][0][i][j]) & (perturbed_data[0][0][i][j] > min_v):\n",
    "        #             perturbed_data[0][0][i][j] = min_v\n",
    "\n",
    "        # ノイズ付き画像を再度分類します\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # 攻撃の成功を確認します\n",
    "        final_pred = output.max(1, keepdim=True)[1] # log-probabilityが最大のインデックスを取得します\n",
    "\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # epsilonが0の場合という特殊なケースを保存\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # あとで可視化するために敵対的サンプルのうちいくつかを保存\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "\n",
    "    # epsilonごとの最終的な精度を算出\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    # 精度と敵対的サンプルを返却\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, device, test_loader, epsilon ):\n",
    "\n",
    "    # 精度カウンター\n",
    "    correct = 0\n",
    "    org_examples = []\n",
    "    adv_examples = []\n",
    "    \n",
    "\n",
    "    # テスト用データセット内の全てのサンプルをループします\n",
    "    for data, target in tqdm(test_loader):\n",
    "\n",
    "        # データとラベルをデバイス（CPUもしくはGPU）に送信します\n",
    "        data, target = data.to(device), target.to(device)\n",
    "    \n",
    "\n",
    "        # テンソルの requires_grad 属性を設定します。攻撃者にとっては重要な設定です。\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # データをモデルに順伝播させます\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # 最大の確率のインデックスを取得します。\n",
    "\n",
    "        # 最初から予測が間違っている場合、攻撃する必要がないため次のイテレーションに進みます。\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # 損失を計算します\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # 既存の勾配を全てゼロにします\n",
    "        model.zero_grad()\n",
    "\n",
    "        # 逆伝播させてモデルの勾配を計算します\n",
    "        loss.backward()\n",
    "\n",
    "        # データの勾配を取得します\n",
    "        data_grad = data.grad.data\n",
    "        \n",
    "        # FGSMによる攻撃の関数を呼び出します\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # ノイズ付き画像を再度分類します\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # 攻撃の成功を確認します\n",
    "        final_pred = output.max(1, keepdim=True)[1] # log-probabilityが最大のインデックスを取得します\n",
    "\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # epsilonが0の場合という特殊なケースを保存\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                org_ex = data.squeeze().detach().cpu().numpy()\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                org_examples.append((init_pred.item(), init_pred.item(), org_ex))\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # あとで可視化するために敵対的サンプルのうちいくつかを保存\n",
    "            if len(adv_examples) < 1:\n",
    "                org_ex = data.squeeze().detach().cpu().numpy()\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                print(final_pred.item())\n",
    "                plt.xticks([], [])\n",
    "                plt.yticks([], [])\n",
    "                plt.imsave(\"fgsm_org.png\", org_ex, cmap=\"gray\")\n",
    "                plt.xticks([], [])\n",
    "                plt.yticks([], [])\n",
    "                plt.imsave(\"fgsm_adv.png\", adv_ex, cmap=\"gray\")\n",
    "                break\n",
    "                # org_examples.append((init_pred.item(), init_pred.item(), org_ex))\n",
    "                # adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "\n",
    "    # epsilonごとの最終的な精度を算出\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    # 精度と敵対的サンプルを返却\n",
    "    return final_acc, org_examples, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epsilon: 0.2\tTest Accuracy = 0 / 10000 = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAADfklEQVR4nO3YsW1CUQxA0f+ijAB1/v6zwBDUyQ5OjyiCBLkSnFNaLlzdwmtmNgD+30d9AMC7EmCAiAADRAQYICLAABEBBoh83rN8OBxm3/cnnQLwms7n88/MHK/ndwV43/ftdDo97iqAN7DWutyae0EARAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQWTPz9+W1vrdtuzzvHICX9DUzx+vhXQEG4HG8IAAiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiv24jG3fvmQi6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_2 = []\n",
    "accuracies = []\n",
    "org_examples = []\n",
    "adv_examples = []\n",
    "\n",
    "# 各epsilonごとにテストを実行\n",
    "for eps in epsilons:\n",
    "    acc, org_ex, adv_ex = test(model, device, test_loader, eps)\n",
    "    accuracies_2.append(acc)\n",
    "    org_examples.append(org_ex)\n",
    "    adv_examples.append(adv_ex)\n",
    "    # acc, ex = test(model, device, test_loader, eps)\n",
    "    # accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 各epsilonでの敵対的なサンプルの例をプロットする\n",
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(org_examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(org_examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = org_examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 各epsilonでの敵対的なサンプルの例をプロットする\n",
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(adv_examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(adv_examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = adv_examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
